# -*- coding: utf-8 -*-
"""Analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10zc5PUBBM2EqG_sfgHq_P43Dl52jjAy_
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

pd.options.display.max_rows = 999
pd.options.display.max_columns = 100

"""# Data Cleaning"""

metrics = pd.read_excel('data/metrics.xlsx')
metrics.head()

metrics.columns

# len(metrics[metrics['Denominator'] > 300])
len(metrics)

data = metrics.copy()
data = data[['EntityID', 'Region', 'Population', 'ID', 'Name', 'Denominator', 'Rate', 'Score']]
data.head()

# look for very low denominators--this will be important later on
gb = adult[adult['Denominator']<100].groupby('ID')
for k in gb.groups.keys():
  group = gb.get_group(k)
  if len(group[group['Denominator'] < 30]) > 0.8*len(group):
    print(k)

# change ID to an integer so we can use as a decent index
data['EntityID'] = data['EntityID'].apply(lambda x: int(x.split()[1]))

data.head()

adult = data[data['Population']=='Adult']
adult.head()

spread_adult = adult.pivot(index='EntityID', columns='ID', values='Rate')
spread_adult.head()

# now get reim data so we can stitch them together
reim = pd.read_csv('data/reimbursements.csv')
reim.head()

reim.columns = [x.replace('\r\n','_') for x in reim.columns]
reim.columns = [x.replace(' ','_') for x in reim.columns]
reim.columns

reim['EntityID'] = reim['EntityID'].apply(lambda x: int(x.split()[1]))

# For now we're only interested in high-level outcomes.
reim = reim[['EntityID',
             'Region',
             'Quality_Score',
             'Quality_Threshold',
             'PMPM_Score',
             'ED_Score',
             'RDM_Score',
             'Total_Potential_$',
             'QA_Potential_$',
             'QA_Earned_$',
             'QA_Missed_$',
             'Adult_QA_Score',
#              'Peds_QA_Score',
#              'Senior_QA_Score',
             'Adult_PMPM',
             'Adult_Exp_PMPM',
             'Adult_ED_Rate',
             'Adult_RDM_Rate'
             ]]
reim.head()

spread_adult_merged = pd.merge(spread_adult, reim,
                              left_on='EntityID',
                              right_on='EntityID')
spread_adult_merged.head()

spread_adult_merged.to_csv('data/adult_spread_data.csv', index=False)

"""# Analysis"""

spread_adult_merged = pd.read_csv('data/adult_spread_data.csv')
sam = spread_adult_merged.copy()
ind_var_index = [i for i in range(1,29)]

names = ["Comprehensive Diabetes Care: Medical Attention for Nephropathy",
"Comprehensive Diabetes Care: Eye Exam (retinal) performed",
"Breast Cancer Screening",
"Colorectal Cancer Screening",
"Cervical Cancer Screening",
"Adult BMI Assessment",
"Comprehensive Diabetes Care: HbA1c Control (<=9%)",
"Medication Adherence for Diabetes Medication",
"Medication Adherence for Hypertension: RASA",
"Medication Adherence for Cholesterol (Statins)",
"Disease-Modifying Anti-Rheumatic Drug Therapy for Rheumatoid Arthritis",
"All-Cause Readmissions: All Products",
"Avoidance of Antibiotic treatment in Adults With Acute Bronchitis",
"Chlamydia Screening in Women",
"Medication Management for People With Asthma",
"Annual Monitoring for Patients on Persistent Medications",
"Statin Therapy for Patients With Cardiovascular Disease",
"Statin Use in Persons with Diabetes",
"Comprehensive Diabetes Care: HbA1c Control (<8.0%)",
"Use of Imaging Studies for Low Back Pain",
"Use of Opioids at High Dosage",
"Use of Opioids from Multiple Providers",
"Use of Opioids from Multiple Pharmacies",
"Use of Opioids from Multiple Pharmacies and Providers",
"Controlling High Blood Pressure",
"Avoid Inappropriate Ambulatory Antibiotic Use",
"Annual EKGs or Cardiac Screening"
]

codes = ['QN02_3', 'QN02_4', 'QN08', 'QN09', 'QN10', 'QN35', 'QN36', 'QN38',
       'QN39', 'QN40', 'QN41', 'QN44', 'QN45', 'QN46', 'QN49', 'QN55', 'QN58',
       'QN60', 'QN64', 'QN69', 'QN70', 'QN71_1', 'QN71_2', 'QN71_3', 'QN76',
       'QN77', 'QN78']

metric_id = list(zip(codes, names))
metric_id

"""## Linear Reg

Test on one.
"""

import pingouin as pg
from sklearn.linear_model import LinearRegression
X = np.array(sam['QN02_3']).reshape(-1,1)
y = sam['Adult_Exp_PMPM']

X.shape

# run the regression
reg = LinearRegression().fit(X,y)

# check the R^2
reg.score(X,y)

# try with pingouin
pg.corr(x=sam.iloc[:,1], y=sam['Adult_Exp_PMPM'])

"""Generalize for all. Check $R^2$."""

# now generalize and get top 5 and bottom 5
y = sam['Adult_Exp_PMPM']
scores = []
for code, name in metric_id:
    X = np.array(sam[code]).reshape(-1,1)
    reg = LinearRegression().fit(X,y)
    scores.append((code, name, reg.score(X,y)))
sort_scores = sorted(scores, key=lambda x: x[2], reverse=True)
top5 = sort_scores[:5]
bottom5 = sort_scores[-5:]

print("Top R^2")
for i in top5:
    print(i)
print()
print("Bottom R^2")
for i in bottom5:
    print(i)

sam.iloc[:,[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,-3]].rcorr(stars=False)

"""## Mult. Linear Reg
Clearly there is some multicollinearity here.
"""

import statsmodels.api as sm
X = sam.iloc[:,1:28]    # set X - independent vars
y = sam['RDM_Score']
X = sm.add_constant(X)

model = sm.OLS(y, X).fit()
predictions = model.predict(X)
model.summary()

from sklearn import linear_model
X = sam.iloc[:,1:28]    # set X - independent vars
y = sam['Adult_Exp_PMPM']

reg = LinearRegression().fit(X,y)

reg.score(X,y)

reg.coef_

reg.intercept_

"""## PCA

First remove any with too many zeroes.
"""

sam = spread_adult_merged.copy()

sam.head()

# sam = spread_adult_merged.copy()
for code, name in metric_id:
    v = sam[code].value_counts()
    if 0 in v.index and v[0] > 0.6*sum(v):
        sam.drop(columns=code, inplace=True)
        
sam.columns

X = sam.iloc[:,1:24]    # set X - independent vars
y = sam['Adult_Exp_PMPM']

train_x, test_x, train_y, test_y = train_test_split(X, y, test_size=0.3, random_state=1)
print(train_x.shape)
print(test_x.shape)
print(train_y.shape)
print(test_y.shape)

from sklearn.decomposition import PCA

for code in X.columns:
    v = X[code].value_counts()
    if 0 in v.index and v[0] > 0.6*sum(v):
        X.drop(columns=code, inplace=True)
        
X.columns

# need to center the data
X.describe()

from sklearn.preprocessing import StandardScaler
sc_X = pd.DataFrame(StandardScaler().fit_transform(X), columns=X.columns)
sc_X.describe()

pca = PCA(n_components=2)
pca.fit(sc_X)

print(pca.explained_variance_ratio_)

two_d_data = pca.transform(X)

two_d_data.shape

y.shape

# plt.style.use('seaborn')
# color using the Adult_Exp_PMPM
plt.figure(figsize=(14,10))
plt.scatter(two_d_data[:,0], two_d_data[:,1], alpha=0.7, s=25, c=y, cmap='plasma')
plt.colorbar()

# add title and axis labels
plt.xlabel("1st component (50.94% of variance)")
plt.ylabel("2nd component (5.35% of variance)")
plt.title("First two principal components, colored by Adult Exp PMPM");

# adds major gridlines
plt.grid(color='grey', linestyle='-', linewidth=0.25, alpha=0.5)

# look at what features are being assigned high weight
print(pca.components_[0])
print(pca.components_[1])

# get in abs value
abs_val_two_d_weights_component_1 = np.abs(pca.components_[0])
abs_val_two_d_weights_component_2 = np.abs(pca.components_[1])

ranking_1 = np.argsort(-abs_val_two_d_weights_component_1)
ranking_2 = np.argsort(-abs_val_two_d_weights_component_2)

# now print out the metrics with highest to lowest absolute weight
print(f'First Component, which explains {np.round(pca.explained_variance_ratio_[0]*100, decimals=2)}% of the variance')
print("="*80)
for r in ranking_1:
    print(X.columns[r], ':', pca.components_[0][r])

print('\n\n')
print(f'Second Component, which explains {np.round(pca.explained_variance_ratio_[1]*100, decimals=2)}% of the variance')
print("="*80)
for r in ranking_2:
    print(X.columns[r], ':', pca.components_[1][r])

"""Let's try coloring by region to see what happens."""

colormap = spread_adult_merged['Region'].copy()

colormap.unique()

colordict = {'WPA': 0, 'NEPA': 1, 'WV': 2, 'CPA': 3, 'DE': 4}
colormap = colormap.apply(lambda x: colordict[x])
colormap.head()

import seaborn as sns

# color by region
plt.figure(figsize=(12,10))
sns.scatterplot(two_d_data[:,0], two_d_data[:,1], hue=colormap, palette="Accent")
# plt.scatter(two_d_data[:,0], two_d_data[:,1], alpha=0.7, c=colormap)

# add title and axis labels
plt.xlabel("1st component (50.94% of variance)")
plt.ylabel("2nd component (5.35% of variance)")
plt.title("First two principal components, colored by Adult Exp PMPM");

# add legend
plt.legend();



# color using the PMPM_Score
plt.figure(figsize=(14,10))
plt.scatter(two_d_data[:,0], two_d_data[:,1], alpha=0.7, s=25, c=spread_adult_merged.PMPM_Score, cmap='plasma')
plt.colorbar()

# add title and axis labels
plt.xlabel("1st component (50.94% of variance)")
plt.ylabel("2nd component (5.35% of variance)")
plt.title("First two principal components, colored by PMPM Score");

# adds major gridlines
plt.grid(color='grey', linestyle='-', linewidth=0.25, alpha=0.5)



# color using the ED_Score
plt.figure(figsize=(14,10))
plt.scatter(two_d_data[:,0], two_d_data[:,1], alpha=0.7, s=25, c=spread_adult_merged.Adult_ED_Rate, cmap='plasma')
plt.colorbar()

# add title and axis labels
plt.xlabel("1st component (50.94% of variance)")
plt.ylabel("2nd component (5.35% of variance)")
plt.title("First two principal components, colored by Adult ED Rate");

# adds major gridlines
plt.grid(color='grey', linestyle='-', linewidth=0.25, alpha=0.5)



# color using the RDM_Score
plt.figure(figsize=(14,10))
plt.scatter(two_d_data[:,0], two_d_data[:,1], alpha=0.7, s=25, c=spread_adult_merged.RDM_Score, cmap='plasma')
plt.colorbar()

# add title and axis labels
plt.xlabel("1st component (50.94% of variance)")
plt.ylabel("2nd component (5.35% of variance)")
plt.title("First two principal components, colored by RDM Score");

# adds major gridlines
plt.grid(color='grey', linestyle='-', linewidth=0.25, alpha=0.5)

cm = spread_adult_merged.Adult_QA_Score.copy()
cm = cm.apply(lambda x: 0 if x=='.' else float(x))

# color using the QA Score
plt.figure(figsize=(14,10))
plt.scatter(two_d_data[:,0], two_d_data[:,1], alpha=0.7, s=25, c=cm.values, cmap='plasma')
plt.colorbar()

# add title and axis labels
plt.xlabel("1st component (50.94% of variance)")
plt.ylabel("2nd component (5.35% of variance)")
plt.title("First two principal components, colored by Adult QA Score");

# adds major gridlines
plt.grid(color='grey', linestyle='-', linewidth=0.25, alpha=0.5)



"""# Pediatric version

## Prep
"""

metrics = pd.read_excel('data/metrics.xlsx')
metrics.head()

metrics.columns

# len(metrics[metrics['Denominator'] > 300])
len(metrics)

data = metrics.copy()
data = data[['EntityID', 'Region', 'Population', 'ID', 'Name', 'Denominator', 'Rate', 'Score']]
data.head()

# change ID to an integer so we can use as a decent index
data['EntityID'] = data['EntityID'].apply(lambda x: int(x.split()[1]))

data.head()

ped = data[data['Population']=='Pediatric']
ped.head()

spread_ped = ped.pivot(index='EntityID', columns='ID', values='Rate')
spread_ped.head()

# now get reim data so we can stitch them together
reim = pd.read_csv('data/reimbursements.csv')
reim.head()

reim.columns = [x.replace('\r\n','_') for x in reim.columns]
reim.columns = [x.replace(' ','_') for x in reim.columns]
reim.columns

reim['EntityID'] = reim['EntityID'].apply(lambda x: int(x.split()[1]))

# For now we're only interested in high-level outcomes.
reim = reim[['EntityID',
             'Region',
             'Quality_Score',
            #  'Quality_Threshold',
             'PMPM_Score',
             'ED_Score',
             'RDM_Score',
            #  'Total_Potential_$',
            #  'QA_Potential_$',
            #  'QA_Earned_$',
            #  'QA_Missed_$',
            #  'Adult_QA_Score',
             'Peds_QA_Score',
#              'Senior_QA_Score',
             'Children_PMPM',
             'Children_Exp_PMPM',
             'Peds_ED_Rate'
             ]]
reim.head()

spread_ped_merged = pd.merge(spread_ped, reim,
                              left_on='EntityID',
                              right_on='EntityID')
spread_ped_merged.head()

spread_ped_merged.to_csv('data/pediatric_spread_data.csv', index=False)

"""## Analysis"""

spread_ped_merged = pd.read_csv('data/pediatric_spread_data.csv', na_values=['.'])
sam = spread_ped_merged.copy()
ind_var_index = [i for i in range(1,12)]
sam.info()

sam.fillna(value=0.0, inplace=True)

import statsmodels.api as sm
X = sam.iloc[:,1:12]    # set X - independent vars
y = sam['RDM_Score']
X = sm.add_constant(X)

model = sm.OLS(y, X).fit()
predictions = model.predict(X)
model.summary()

from sklearn.decomposition import PCA

X = sam.iloc[:,1:12]    # set X - independent vars
y = sam['Children_Exp_PMPM']

for code in X.columns:
    v = X[code].value_counts()
    if 0 in v.index and v[0] > 0.6*sum(v):
        X.drop(columns=code, inplace=True)
        
X.columns

# need to center the data
X.describe()

from sklearn.preprocessing import StandardScaler
sc_X = pd.DataFrame(StandardScaler().fit_transform(X), columns=X.columns)
sc_X.describe()

pca = PCA(n_components=2)
pca.fit(sc_X)

print(pca.explained_variance_ratio_)

two_d_data = pca.transform(X)

two_d_data.shape

y.shape

# plt.style.use('seaborn')
# color using the Adult_Exp_PMPM
plt.figure(figsize=(14,10))
plt.scatter(two_d_data[:,0], two_d_data[:,1], alpha=0.7, s=25, c=y, cmap='plasma')
plt.colorbar()

# add title and axis labels
plt.xlabel(f"1st component ({np.round(pca.explained_variance_ratio_[0]*100, 2)}% of variance)")
plt.ylabel(f"2nd component ({np.round(pca.explained_variance_ratio_[1]*100, 2)}% of variance)")
plt.title("First two principal components, colored by Children Exp PMPM");

# adds major gridlines
plt.grid(color='grey', linestyle='-', linewidth=0.25, alpha=0.5)

# look at what features are being assigned high weight
print(pca.components_[0])
print(pca.components_[1])

# get in abs value
abs_val_two_d_weights_component_1 = np.abs(pca.components_[0])
abs_val_two_d_weights_component_2 = np.abs(pca.components_[1])

ranking_1 = np.argsort(-abs_val_two_d_weights_component_1)
ranking_2 = np.argsort(-abs_val_two_d_weights_component_2)

# now print out the metrics with highest to lowest absolute weight
print(f'First Component, which explains {np.round(pca.explained_variance_ratio_[0]*100, decimals=2)}% of the variance')
print("="*80)
for r in ranking_1:
    print(X.columns[r], ':', pca.components_[0][r])

print('\n\n')
print(f'Second Component, which explains {np.round(pca.explained_variance_ratio_[1]*100, decimals=2)}% of the variance')
print("="*80)
for r in ranking_2:
    print(X.columns[r], ':', pca.components_[1][r])

"""Let's try coloring by region to see what happens."""

colormap = spread_ped_merged['Region'].copy()

colormap.unique()

import seaborn as sns

# color by region
plt.figure(figsize=(12,10))
sns.scatterplot(two_d_data[:,0], two_d_data[:,1], hue=colormap, palette="Accent")
# plt.scatter(two_d_data[:,0], two_d_data[:,1], alpha=0.7, c=colormap)

# add title and axis labels
plt.xlabel(f"1st component ({np.round(pca.explained_variance_ratio_[0]*100, 2)}% of variance)")
plt.ylabel(f"2nd component ({np.round(pca.explained_variance_ratio_[1]*100, 2)}% of variance)")
plt.title("First two principal components, colored by Region");

# add legend
plt.legend();

# color using the QA_Score
plt.figure(figsize=(14,10))
plt.scatter(two_d_data[:,0], two_d_data[:,1], alpha=0.7, s=25, c=spread_ped_merged.Peds_QA_Score, cmap='plasma')
plt.colorbar()

# add title and axis labels
plt.xlabel(f"1st component ({np.round(pca.explained_variance_ratio_[0]*100, 2)}% of variance)")
plt.ylabel(f"2nd component ({np.round(pca.explained_variance_ratio_[1]*100, 2)}% of variance)")
plt.title("First two principal components, colored by Peds QA Score");

# adds major gridlines
plt.grid(color='grey', linestyle='-', linewidth=0.25, alpha=0.5)

# color using the ED_Score
plt.figure(figsize=(14,10))
plt.scatter(two_d_data[:,0], two_d_data[:,1], alpha=0.7, s=25, c=spread_ped_merged.Peds_ED_Rate, cmap='plasma')
plt.colorbar()

# add title and axis labels
plt.xlabel(f"1st component ({np.round(pca.explained_variance_ratio_[0]*100, 2)}% of variance)")
plt.ylabel(f"2nd component ({np.round(pca.explained_variance_ratio_[1]*100, 2)}% of variance)")
plt.title("First two principal components, colored by Peds ED Rate");

# adds major gridlines
plt.grid(color='grey', linestyle='-', linewidth=0.25, alpha=0.5)



# color using the RDM_Score
plt.figure(figsize=(14,10))
plt.scatter(two_d_data[:,0], two_d_data[:,1], alpha=0.7, s=25, c=spread_ped_merged.RDM_Score, cmap='plasma')
plt.colorbar()

# add title and axis labels
plt.xlabel(f"1st component ({np.round(pca.explained_variance_ratio_[0]*100, 2)}% of variance)")
plt.ylabel(f"2nd component ({np.round(pca.explained_variance_ratio_[1]*100, 2)}% of variance)")
plt.title("First two principal components, colored by RDM Score");

# adds major gridlines
plt.grid(color='grey', linestyle='-', linewidth=0.25, alpha=0.5)

"""# Senior version

## Prep
"""

metrics = pd.read_excel('data/metrics.xlsx')
metrics.head()

metrics.columns

# len(metrics[metrics['Denominator'] > 300])
len(metrics)

data = metrics.copy()
data = data[['EntityID', 'Region', 'Population', 'ID', 'Name', 'Denominator', 'Rate', 'Score']]
data.head()

# change ID to an integer so we can use as a decent index
data['EntityID'] = data['EntityID'].apply(lambda x: int(x.split()[1]))

data.head()

sen = data[data['Population']=='Senior']
sen.head()

spread_sen = sen.pivot(index='EntityID', columns='ID', values='Rate')
spread_sen.head()

# now get reim data so we can stitch them together
reim = pd.read_csv('data/reimbursements.csv')
reim.head()

reim.columns = [x.replace('\r\n','_') for x in reim.columns]
reim.columns = [x.replace(' ','_') for x in reim.columns]
reim.columns

reim['EntityID'] = reim['EntityID'].apply(lambda x: int(x.split()[1]))

# For now we're only interested in high-level outcomes.
reim = reim[['EntityID',
             'Region',
             'Quality_Score',
            #  'Quality_Threshold',
             'PMPM_Score',
             'ED_Score',
             'RDM_Score',
            #  'Total_Potential_$',
            #  'QA_Potential_$',
            #  'QA_Earned_$',
            #  'QA_Missed_$',
            #  'Adult_QA_Score',
            #  'Peds_QA_Score',
             'Senior_QA_Score',
             'MA_PMPM',
             'MA_Exp_PMPM',
             'Senior_ED_Rate',
             'Senior_RDM_Rate'
             ]]
reim.head()

spread_sen_merged = pd.merge(spread_sen, reim,
                              left_on='EntityID',
                              right_on='EntityID')
spread_sen_merged.head()

spread_sen_merged.to_csv('data/senior_spread_data.csv', index=False)

"""## Analysis"""

spread_sen_merged = pd.read_csv('data/senior_spread_data.csv', na_values=['.'])
sam = spread_sen_merged.copy()
ind_var_index = [i for i in range(1,31)]
sam.info()

sam.fillna(value=0.0, inplace=True)

import statsmodels.api as sm
X = sam.iloc[:,1:31]    # set X - independent vars
y = sam['Senior_RDM_Rate']
X = sm.add_constant(X)

model = sm.OLS(y, X).fit()
predictions = model.predict(X)
model.summary()

from sklearn.decomposition import PCA

X = sam.iloc[:,1:31]    # set X - independent vars
y = sam['Senior_QA_Score']

for code in X.columns:
    v = X[code].value_counts()
    if 0 in v.index and v[0] > 0.6*sum(v):
        X.drop(columns=code, inplace=True)
        
X.columns

# need to center the data
X.describe()

from sklearn.preprocessing import StandardScaler
sc_X = pd.DataFrame(StandardScaler().fit_transform(X), columns=X.columns)
sc_X.describe()

pca = PCA(n_components=2)
pca.fit(sc_X)

print(pca.explained_variance_ratio_)

two_d_data = pca.transform(X)

two_d_data.shape

y.shape

# plt.style.use('seaborn')
# color using the Adult_Exp_PMPM
plt.figure(figsize=(14,10))
plt.scatter(two_d_data[:,0], two_d_data[:,1], alpha=0.7, s=25, c=spread_sen_merged.MA_Exp_PMPM, cmap='plasma')
plt.colorbar()

# add title and axis labels
plt.xlabel(f"1st component ({np.round(pca.explained_variance_ratio_[0]*100, 2)}% of variance)")
plt.ylabel(f"2nd component ({np.round(pca.explained_variance_ratio_[1]*100, 2)}% of variance)")
plt.title("First two principal components, colored by MA Exp PMPM");

# adds major gridlines
plt.grid(color='grey', linestyle='-', linewidth=0.25, alpha=0.5)

# look at what features are being assigned high weight
print(pca.components_[0])
print(pca.components_[1])

# get in abs value
abs_val_two_d_weights_component_1 = np.abs(pca.components_[0])
abs_val_two_d_weights_component_2 = np.abs(pca.components_[1])

ranking_1 = np.argsort(-abs_val_two_d_weights_component_1)
ranking_2 = np.argsort(-abs_val_two_d_weights_component_2)

# now print out the metrics with highest to lowest absolute weight
print(f'First Component, which explains {np.round(pca.explained_variance_ratio_[0]*100, decimals=2)}% of the variance')
print("="*80)
for r in ranking_1:
    print(X.columns[r], ':', pca.components_[0][r])

print('\n\n')
print(f'Second Component, which explains {np.round(pca.explained_variance_ratio_[1]*100, decimals=2)}% of the variance')
print("="*80)
for r in ranking_2:
    print(X.columns[r], ':', pca.components_[1][r])

"""Let's try coloring by region to see what happens."""

colormap = spread_sen_merged['Region'].copy()

colormap.unique()

import seaborn as sns

# color by region
plt.figure(figsize=(12,10))
sns.scatterplot(two_d_data[:,0], two_d_data[:,1], hue=colormap, palette="Accent")
# plt.scatter(two_d_data[:,0], two_d_data[:,1], alpha=0.7, c=colormap)

# add title and axis labels
plt.xlabel(f"1st component ({np.round(pca.explained_variance_ratio_[0]*100, 2)}% of variance)")
plt.ylabel(f"2nd component ({np.round(pca.explained_variance_ratio_[1]*100, 2)}% of variance)")
plt.title("First two principal components, colored by Region");

# add legend
plt.legend();

# color using the QA_Score
plt.figure(figsize=(14,10))
plt.scatter(two_d_data[:,0], two_d_data[:,1], alpha=0.7, s=25, c=spread_sen_merged.Senior_QA_Score, cmap='plasma')
plt.colorbar()

# add title and axis labels
plt.xlabel(f"1st component ({np.round(pca.explained_variance_ratio_[0]*100, 2)}% of variance)")
plt.ylabel(f"2nd component ({np.round(pca.explained_variance_ratio_[1]*100, 2)}% of variance)")
plt.title("First two principal components, colored by Senior QA Score");

# adds major gridlines
plt.grid(color='grey', linestyle='-', linewidth=0.25, alpha=0.5)

# color using the ED_Score
plt.figure(figsize=(14,10))
plt.scatter(two_d_data[:,0], two_d_data[:,1], alpha=0.7, s=25, c=spread_sen_merged.Senior_ED_Rate, cmap='plasma')
plt.colorbar()

# add title and axis labels
plt.xlabel(f"1st component ({np.round(pca.explained_variance_ratio_[0]*100, 2)}% of variance)")
plt.ylabel(f"2nd component ({np.round(pca.explained_variance_ratio_[1]*100, 2)}% of variance)")
plt.title("First two principal components, colored by Senior ED Rate");

# adds major gridlines
plt.grid(color='grey', linestyle='-', linewidth=0.25, alpha=0.5)

# color using the RDM_Score
plt.figure(figsize=(14,10))
plt.scatter(two_d_data[:,0], two_d_data[:,1], alpha=0.7, s=25, c=spread_sen_merged.Senior_RDM_Rate, cmap='plasma')
plt.colorbar()

# add title and axis labels
plt.xlabel(f"1st component ({np.round(pca.explained_variance_ratio_[0]*100, 2)}% of variance)")
plt.ylabel(f"2nd component ({np.round(pca.explained_variance_ratio_[1]*100, 2)}% of variance)")
plt.title("First two principal components, colored by RDM Score");

# adds major gridlines
plt.grid(color='grey', linestyle='-', linewidth=0.25, alpha=0.5)

